{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu May 16 00:56:41 2019\n",
    "\n",
    "@author: liuqitao\n",
    "\"\"\"\n",
    "\n",
    "import jieba\n",
    "import src.constant as cs\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "from collections import defaultdict\n",
    "#一次性求出一组训练文本的相似度\n",
    "def tfidf(fileurls):\n",
    "    result = []\n",
    "    for temp in fileurls:\n",
    "        sims = similarity(temp)\n",
    "        result.append(sims)\n",
    "    return result\n",
    "        \n",
    "def similarity(fileurl):\n",
    " fileurl1 = cs.file_url_app+fileurl[0]\n",
    " fileurl2 = cs.file_url_app+fileurl[1]\n",
    " # 加载文档\n",
    " d1 = open(fileurl1).read()\n",
    " d2 = open(cs.file_remark).read()\n",
    " # 对文档进行切词\n",
    " data1 = jieba.cut(d1)\n",
    " data11 = \"\"\n",
    " for i in data1:\n",
    "  data11 += i + \" \"\n",
    " data2 = jieba.cut(d2)\n",
    " data22 = \"\"\n",
    " for i in data2:\n",
    "  data22 += i + \" \" \n",
    " # 将两个字符串放入list\n",
    " documents = [data11,data22]\n",
    " # 将list中每个字符串切分，list里套list\n",
    " texts = [[word for word in docu.split(\" \")] for docu in documents]\n",
    " # 进行词频统计，类似于wordcount,导包,其实这个频率统计的唯一意义是，为了在后面筛选出那些频率高的词，剔除掉频率低的词，这个词频统计与最后的稀疏矩阵的建立没有任何关系\n",
    " frequency = defaultdict(int)\n",
    " for t1 in texts:\n",
    "  for t2 in t1:\n",
    "   frequency[t2] += 1\n",
    " texts = [[t2 for t2 in t1 if frequency[t2] > 3] for t1 in texts]\n",
    " dictionary = corpora.Dictionary(texts)\n",
    " #这是对比文件\n",
    " d3 = open(fileurl2).read()\n",
    " data3 = jieba.cut(d3)\n",
    " data33 = \"\"\n",
    " for t in data3:\n",
    "  data33+=t+\" \"\n",
    " #print(data33)\n",
    " new_doc =data33\n",
    " #通过字典将当前文档转化为稀疏向量\n",
    " new_vec=dictionary.doc2bow(new_doc.split())\n",
    " #print(new_vec)\n",
    " #将之前的数据也变成稀疏向量\n",
    " new_corpus = [dictionary.doc2bow(text)for text in texts]\n",
    " #对原始文档进行tf-idf模型计算，获取tf-idf值\n",
    " tfidf = models.TfidfModel(new_corpus)\n",
    " #得到语料库的特征数长度\n",
    " featureNum=len(dictionary.token2id.keys())\n",
    " #计算稀疏矩阵相似度\n",
    " index=similarities.SparseMatrixSimilarity(tfidf[new_corpus],num_features=featureNum)\n",
    " sims=index[tfidf[new_vec]]\n",
    " #print(\"sims:\")\n",
    " print(sims)\n",
    " return sims[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
